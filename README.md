# RAG System with Llama_Index Technology

Welcome to the **RAG System** repository, showcasing the powerful integration of Llama_Index technology and the Ollama Local Model (Llama3.1:8b). This cutting-edge Retrieval-Augmented Generation (RAG) system is designed to revolutionize document interaction and intelligent chat management.

## Overview

The RAG system leverages advanced AI technologies to offer a seamless and intuitive experience for handling documents and managing multiple chats. Built on **Streamlit**, our system provides a robust interface similar to ChatGPT, but with enhanced functionalities tailored for precise document-based queries.

## Key Features

- **Multiple Chats**: Create and manage multiple chat sessions, each associated with different documents. Each chat operates independently, ensuring accurate answers based on the specific document context.
  
- **Contextual Answers**: Obtain responses directly from the relevant document content. Our system avoids cross-context confusion by providing answers solely based on the document in question.
  
- **Local Storage**: Benefit from local storage for both document embeddings and chat history. Your interactions and document contexts are securely saved and preserved for future sessions.
  
- **User-Friendly Interface**: Experience a streamlined, intuitive interface designed for efficiency and ease of use, similar to ChatGPT but optimized for document management.

## Requirements

- Python 3.10
- Streamlit
- llama-index-core
- llama-index-readers-file
- llama-index-llms-ollama
- llama-index-embeddings-huggingface

Install the required packages using pip:

```bash
pip install streamlit llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-embeddings-huggingface
```

## Acknowledgement

- Ollama
- llama-index
- streamlit

### Owner
Hasnain Muavia
